{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Training the Transformer Model</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Scientist.: Dr.Eddy Giusepe Chirinos Isidro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reunimos o [modelo Transformer completo](https://machinelearningmastery.com/joining-the-transformer-encoder-and-decoder-and-masking) e agora estamos prontos para treiná-lo para tradução automática neural. Usaremos um Dataset de treinamento para essa finalidade, que contém pares de frases curtas em `inglês` e `alemão`. Também revisitaremos o papel do mascaramento no cálculo das métricas de *accuracy* e **Loss** durante o processo de treinamento. \n",
    "\n",
    "Neste script, você aprenderá como treinar o modelo `Transformer` para **tradução automática neural**. Os pontos a estudar são: \n",
    "\n",
    "* Como preparar o conjunto de Dados de treinamento\n",
    "\n",
    "* Como aplicar uma `máscara de preenchimento` (Padding Mask) aos cálculos de Loss e accuracy\n",
    "\n",
    "* Como treinar o modelo Transformer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparando o conjunto de dados de treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para isso, você pode consultar um tutorial anterior que aborda o material sobre como [preparar os dados de texto](https://machinelearningmastery.com/develop-neural-machine-translation-system-keras/) para treinamento. \n",
    "\n",
    "Você também usará um Dataset que contém pares de frases curtas em `Inglês` e `Alemão`, que você pode [baixar aqui](https://github.com/Rishav09/Neural-Machine-Translation-System/blob/master/english-german-both.pkl). Este Dataset específico já foi limpo removendo caracteres não-imprimíveis e não-alfabéticos e caracteres de pontuação, normalizando ainda mais todos os caracteres Unicode para `ASCII` e **alterando todas as letras maiúsculas para minúsculas**. Portanto, você pode pular a etapa de limpeza, que geralmente faz parte do processo de preparação de dados. No entanto, se você usar um conjunto de dados que não seja facilmente limpo, consulte o [tutorial anterior](https://machinelearningmastery.com/develop-neural-machine-translation-system-keras/) para aprender como fazer isso.\n",
    "\n",
    "\n",
    "Vamos prosseguir criando a classe `PrepareDataset` que implementa os seguintes passos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color=\"orange\">Carrega o Dataset de um nome de arquivo especificado.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['i like both', 'ich mag beide'],\n",
       "       ['she misses him', 'er fehlt ihr'],\n",
       "       ['i followed him', 'ich folgte ihm'],\n",
       "       ...,\n",
       "       ['tom is cooking', 'tom kocht'],\n",
       "       ['youre upset', 'sie sind besturzt'],\n",
       "       ['do you see me', 'sehen sie mich']], dtype='<U370')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://github.com/Rishav09/Neural-Machine-Translation-System\n",
    "\n",
    "from pickle import load\n",
    "\n",
    "clean_dataset = load(open('/home/eddygiusepe/24_Transformers_NLP/NLP_Transformers/Training_the_Transformer_Model/english-german-both.pkl', 'rb'))\n",
    "clean_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['i like both', 'ich mag beide'], dtype='<U370')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color=\"orange\">Seleciona o número de sentenças a serem usadas no conjunto de dados. Como o conjunto de dados é grande, você reduzirá seu tamanho para limitar o tempo de treinamento. No entanto, você pode explorar usando o conjunto de dados completo como uma extensão deste tutorial.</font>\n",
    "\n",
    "```\n",
    "dataset = clean_dataset[:self.n_sentences, :]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">Acrescenta tokens de início (`<START>`) e end-of-string - fim de string  (`<EOS>`) a cada sentença. Por exemplo, a frase em inglês, `i like to run`, agora se torna, `<START> i like to run <EOS>`. Isso também se aplica à sua tradução correspondente em Alemão, `ich gehe gerne joggen`, que agora se torna, `<START> ich gehe gerne joggen <EOS>`.</font>\n",
    "\n",
    "```\n",
    "for i in range(dataset[:, 0].size):\n",
    "\tdataset[i, 0] = \"<START> \" + dataset[i, 0] + \" <EOS>\"\n",
    "\tdataset[i, 1] = \"<START> \" + dataset[i, 1] + \" <EOS>\"\n",
    "```    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('venv_transformers': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "995997e0fa455d01783bd0f7e00bfa7ac3c67ebd3b417bdb15c32058a2eecebe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
