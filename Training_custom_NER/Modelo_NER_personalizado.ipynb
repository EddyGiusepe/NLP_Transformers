{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Training Custom NER Model Using Flair</h1>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data scientist.: Dr.Eddy Giusepe Chirinos Isidro"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Começamos estudando o modelo treinado em `Conll-03` (`NER de 4 classes`). Para mais detalhes pode seguir o seguinte tutorial:\n",
    "\n",
    "* [Treinando NER customizado](https://medium.com/thecyphy/training-custom-ner-model-using-flair-df1f9ea9c762)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Flair](https://github.com/flairNLP/flair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-14 23:11:22,675 loading file /home/eddygiusepe/.flair/models/ner-english/4f4cdab26f24cb98b732b389e6cebc646c36f54cfd6e0b7d3b90b25656e4262f.8baa8ae8795f4df80b28e7f7b61d788ecbb057d1dc85aacb316f1bd02837a4a4\n",
      "2022-12-14 23:11:25,000 SequenceTagger predicts: Dictionary with 20 tags: <unk>, O, S-ORG, S-MISC, B-PER, E-PER, S-LOC, B-ORG, E-ORG, I-PER, S-PER, B-MISC, I-MISC, E-MISC, I-ORG, B-LOC, E-LOC, I-LOC, <START>, <STOP>\n",
      "Sentence: \"George Washington went to Washington state and Francisco Pizarro went to Perú .\" → [\"George Washington\"/PER, \"Washington\"/LOC, \"Francisco Pizarro\"/PER, \"Perú\"/LOC]\n",
      "Span[0:2]: \"George Washington\" → PER (0.9993)\n",
      "Span[4:5]: \"Washington\" → LOC (0.9614)\n",
      "Span[7:9]: \"Francisco Pizarro\" → PER (0.9996)\n",
      "Span[11:12]: \"Perú\" → LOC (0.9942)\n"
     ]
    }
   ],
   "source": [
    "from flair.models import SequenceTagger\n",
    "from flair.data import Sentence\n",
    "\n",
    "# Carregamos o Modelo\n",
    "tagger = SequenceTagger.load('ner')\n",
    "\n",
    "sentence = Sentence('George Washington went to Washington state and Francisco Pizarro went to Perú.')\n",
    "\n",
    "# Prever tags NER\n",
    "tagger.predict(sentence)\n",
    "\n",
    "# Print da sentence com a tag predita\n",
    "print(sentence.to_tagged_string())\n",
    "\n",
    "for entity in sentence.get_spans('ner'):\n",
    "    print(entity)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Além disso, podemos obter uma `pontuação de confiança` de cada uma das entidades previstas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'George Washington went to Washington state and Francisco Pizarro went to Perú.', 'ner': [{'value': 'PER', 'confidence': 0.9993289113044739}, {'value': 'LOC', 'confidence': 0.9613563418388367}, {'value': 'PER', 'confidence': 0.999558836221695}, {'value': 'LOC', 'confidence': 0.994195282459259}]}\n"
     ]
    }
   ],
   "source": [
    "print(sentence.to_dict(tag_type='ner'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criação de nossos Dados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mas por que `treinar` os próprios `taggers` de sequência? Em minha carreira profissional relativamente jovem, me deparei com problemas onde havia algumas frases/sequência textual, a serem extraídas de um documento inteiro. \n",
    "\n",
    "`Por exemplo:` \n",
    "\n",
    "considere um contrato, não apenas qualquer tipo de contrato, mas um contrato de arrendamento. Nesses contratos, as `“entidades”` como o nome das partes envolvidas, a data de rescisão, etc., tornam as informações de interesse. Agora, imagine o cenário em que esses contratos `não são estruturados`. Se eles fossem estruturados, poderíamos apenas extrair as referidas entidades escrevendo algumas regras básicas.\n",
    "\n",
    "\n",
    "Agora, para criar um modelo que possa encontrar essas entidades a partir do texto fornecido, primeiro precisamos criar um `corpus de treinamento`. \n",
    "\n",
    "\n",
    "Vamos dar uma olhada rápida em como esse corpus é lido."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "from flair.data import Corpus\n",
    "from flair.datasets import ColumnCorpus\n",
    "\n",
    "\n",
    "# Definimos as colunas\n",
    "columns = {0: 'text', 1: 'ner'}\n",
    "\n",
    "# Esta é a pasta onde residem os arquivos train, dev e test\n",
    "data_folder = '/home/eddygiusepe/Imagens/Eddy_codigos/NLP_Transformers/Training_custom_NER/data'\n",
    "\n",
    "# Inicie um corpus usando formato de coluna, pasta de dados e os nomes dos arquivos train, dev e test\n",
    "corpus: Corpus = ColumnCorpus(data_folder, columns,\n",
    "                              train_file='train.txt',\n",
    "                              test_file='test.txt',\n",
    "                              dev_file='dev.txt') \n",
    "\n",
    "```                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>annotation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Horses are too tall and they pretend to care a...</td>\n",
       "      <td>[(Horses, ANIMAL)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Who is Shaka Khan?</td>\n",
       "      <td>[(Shaka Khan, PERSON)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I like London and Berlin.</td>\n",
       "      <td>[(London, LOCATION), (Berlin, LOCATION)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>There is a banyan tree in the courtyard</td>\n",
       "      <td>[(banyan tree, TREE)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Horses are too tall and they pretend to care a...   \n",
       "1                                 Who is Shaka Khan?   \n",
       "2                          I like London and Berlin.   \n",
       "3            There is a banyan tree in the courtyard   \n",
       "\n",
       "                                 annotation  \n",
       "0                        [(Horses, ANIMAL)]  \n",
       "1                    [(Shaka Khan, PERSON)]  \n",
       "2  [(London, LOCATION), (Berlin, LOCATION)]  \n",
       "3                     [(banyan tree, TREE)]  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.DataFrame([[\"Horses are too tall and they pretend to care about your feelings\", [(\"Horses\", \"ANIMAL\")]],\n",
    "                  [\"Who is Shaka Khan?\", [(\"Shaka Khan\", \"PERSON\")]],\n",
    "                  [\"I like London and Berlin.\", [(\"London\", \"LOCATION\"), (\"Berlin\", \"LOCATION\")]],\n",
    "                  [\"There is a banyan tree in the courtyard\", [(\"banyan tree\", \"TREE\")]]], columns=['text', 'annotation'])\n",
    "\n",
    "data.head()                  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lendo o corpus"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, estamos prontos para carregar o corpus que criamos e começar com o treinamento. Vamos começar carregando nosso corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-15 00:45:07,410 Reading data from /home/eddygiusepe/Imagens/Eddy_codigos/NLP_Transformers/Training_custom_NER/data\n",
      "2022-12-15 00:45:07,412 Train: /home/eddygiusepe/Imagens/Eddy_codigos/NLP_Transformers/Training_custom_NER/data/train.txt\n",
      "2022-12-15 00:45:07,414 Dev: /home/eddygiusepe/Imagens/Eddy_codigos/NLP_Transformers/Training_custom_NER/data/dev.txt\n",
      "2022-12-15 00:45:07,415 Test: /home/eddygiusepe/Imagens/Eddy_codigos/NLP_Transformers/Training_custom_NER/data/test.txt\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Corpus\n",
    "from flair.datasets import ColumnCorpus\n",
    "\n",
    "\n",
    "# Definimos as colunas\n",
    "columns = {0: 'text', 1: 'ner'}\n",
    "\n",
    "# Esta é a pasta onde residem os arquivos train, dev e test\n",
    "data_folder = '/home/eddygiusepe/Imagens/Eddy_codigos/NLP_Transformers/Training_custom_NER/data'\n",
    "\n",
    "# Inicie um corpus usando formato de coluna, pasta de dados e os nomes dos arquivos train, dev e test\n",
    "corpus: Corpus = ColumnCorpus(data_folder, columns,\n",
    "                              train_file='train.txt',\n",
    "                              test_file='test.txt',\n",
    "                              dev_file='dev.txt') "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que carregamos nosso corpus, podemos usar este objeto corpus para obter suas informações como:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(len(corpus.train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: \"Horses are too tall and they pretend to care about your feelings\" → [\"Horses\"/ANIMAL]\n"
     ]
    }
   ],
   "source": [
    "print(corpus.train[0].to_tagged_string('ner'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuando, a próxima coisa é definir a `tag` que queremos que nosso modelo seja capaz de prever e criar o dicionário de tags, que é apenas todos os rótulos disponíveis no corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-15 01:53:07,371 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:00, 7172.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-15 01:53:07,441 Dictionary created for label 'ner' with 5 values: LOCATION (seen 2 times), ANIMAL (seen 1 times), PERSON (seen 1 times), TREE (seen 1 times)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# tag para prever\n",
    "tag_type = 'ner'\n",
    "\n",
    "# Fazer dicionário de tags a partir do corpus\n",
    "tag_dictionary = corpus.make_label_dictionary(label_type=tag_type)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A próxima coisa é cuidar das `Embeddings`. A beleza do talento está em tudo o que ele permite que você faça com os `Embeddings`. Você pode escolher entre vários modelos pré-treinados para criar `Embeddings`, até mesmo empilhar os referidos `Embeddings` de talento com `BERT`, `ELMO` e outros enfeites poderosos usando a classe `StackedEmbedding`. E obviamente, treine seus próprios `Embeddings`. Ainda dentro do escopo deste blog, vamos avançar com o treinamento. Os detalhes dos `Embeddings` são maravilhosamente documentados [aqui](https://github.com/flairNLP/flair/blob/master/resources/docs/TUTORIAL_3_WORD_EMBEDDING.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.embeddings import WordEmbeddings, StackedEmbeddings, TokenEmbeddings\n",
    "from typing import List\n",
    "\n",
    "\n",
    "embedding_types : List[TokenEmbeddings] = [\n",
    "        WordEmbeddings('glove'),\n",
    "        ## other embeddings\n",
    "        ]\n",
    "embeddings : StackedEmbeddings = StackedEmbeddings(\n",
    "                                 embeddings=embedding_types)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O próximo passo é inicializar o `Sequence Tagger`. Conceitualmente falando, o que é treinado no back-end é uma `LSTM bidirecional`. `Flair` permite que você passe uma `flag` (sinalizador) para usar os [campos aleatórios condicionais](https://en.wikipedia.org/wiki/Conditional_random_field) também. Vamos definir o referido tagger e ver a arquitetura também."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-15 01:53:31,946 SequenceTagger predicts: Dictionary with 17 tags: O, S-LOCATION, B-LOCATION, E-LOCATION, I-LOCATION, S-ANIMAL, B-ANIMAL, E-ANIMAL, I-ANIMAL, S-PERSON, B-PERSON, E-PERSON, I-PERSON, S-TREE, B-TREE, E-TREE, I-TREE\n",
      "SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings(\n",
      "      'glove'\n",
      "      (embedding): Embedding(400001, 100)\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (rnn): LSTM(100, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=19, bias=True)\n",
      "  (loss_function): ViterbiLoss()\n",
      "  (crf): CRF()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from flair.models import SequenceTagger\n",
    "\n",
    "tagger : SequenceTagger = SequenceTagger(hidden_size=256,\n",
    "                                       embeddings=embeddings,\n",
    "                                       tag_dictionary=tag_dictionary,\n",
    "                                       tag_type=tag_type,\n",
    "                                       use_crf=True) # CRF pode levar em consideração o contexto\n",
    "\n",
    "print(tagger)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Flair` ainda não deixou de ser incrível, tudo o que resta fazer agora é escrever exatamente mais três linhas de código para criar mágica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.trainers import ModelTrainer\n",
    "\n",
    "\n",
    "trainer : ModelTrainer = ModelTrainer(tagger, corpus)\n",
    "\n",
    "trainer.train('resources/taggers/example-ner',\n",
    "              learning_rate=0.1,\n",
    "              mini_batch_size=32,\n",
    "              max_epochs=150)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Isso define nosso modelo de treinamento`. Agora, há algumas coisas a serem observadas. Lembre-se de que, ao criar o objeto de corpus, passamos na validação e nos dados de teste ali mesmo? Isso porque o `flair` internamente faz muitas coisas por você, durante o treino e até mesmo após o treino. Ele cria um novo diretório chamado `resources` em seu diretório de trabalho atual, onde você encontrará tudo, desde os `logs de treinamento`, `informações da Loss` até as `previsões no conjunto de testes` com uma pontuação de confiança. Sob o mesmo diretório em `'resources/taggers/example-ner'` nosso modelo será salvo."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">Por fim, temos um modelo treinado e agora podemos `usá-lo para prever as tags` de uma nova sequência de texto. Isso novamente pode ser feito em algumas linhas mostradas no trecho a seguir.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-15 02:08:25,193 loading file /home/eddygiusepe/Imagens/Eddy_codigos/NLP_Transformers/Training_custom_NER/resources/taggers/example-ner/final-model.pt\n",
      "2022-12-15 02:08:25,727 SequenceTagger predicts: Dictionary with 19 tags: O, S-LOCATION, B-LOCATION, E-LOCATION, I-LOCATION, S-ANIMAL, B-ANIMAL, E-ANIMAL, I-ANIMAL, S-PERSON, B-PERSON, E-PERSON, I-PERSON, S-TREE, B-TREE, E-TREE, I-TREE, <START>, <STOP>\n",
      "Sentence: \"I life in london !\" → [\"london\"/LOCATION]\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "\n",
    "# load the trained model\n",
    "model = SequenceTagger.load('/home/eddygiusepe/Imagens/Eddy_codigos/NLP_Transformers/Training_custom_NER/resources/taggers/example-ner/final-model.pt')\n",
    "\n",
    "# create example sentence\n",
    "sentence = Sentence('I life in london!')\n",
    "\n",
    "# predict the tags\n",
    "model.predict(sentence)\n",
    "print(sentence.to_tagged_string())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "744cf54c6e08528d59b17d69482cd9cfecb0ea2489e1abb457edfe7bddc9bd30"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
