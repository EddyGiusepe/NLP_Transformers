{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">NER básico</h1>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Scientist.: Dr.Eddy Giusepe Chirinos Isidro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizerFast, DistilBertTokenizerFast, BatchEncoding, PreTrainedTokenizerFast, TrainingArguments, Trainer\n",
    "from transformers import BertForTokenClassification, DistilBertForTokenClassification\n",
    "from tokenizers import Encoding\n",
    "\n",
    "import itertools\n",
    "from typing import List, Any, Dict, Union, Set\n",
    "import json\n",
    "from pprint import pprint\n",
    "import os\n",
    "import gc\n",
    "from dataclasses import dataclass\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FORMATO_NER_IOB: str = 'IOB'\n",
    "FORMATO_NER_BILOU: str = 'BILOU'\n",
    "IGNORE_LABEL_MODEL_ID: int=-100\n",
    "IGNORE_LABEL: str='[IGNORE]'\n",
    "\n",
    "GDRIVE_PATH:str = '/home/eddygiusepe/Imagens/Eddy_codigos/NLP_Transformers/NER_BERT_Deep_Learning/basic_NER_BERT'\n",
    "DATASET_DDI_TRAIN:str = os.path.join(GDRIVE_PATH, 'dataset', 'ddi_train.json')\n",
    "DATASET_DDI_TEST:str = os.path.join(GDRIVE_PATH, 'dataset', 'ddi_test.json')\n",
    "DATASET_WNUT:str = os.path.join(GDRIVE_PATH, 'dataset', 'wnut17train.conll')\n",
    "\n",
    "\n",
    "MODEL_BASE: str = 'distilbert-base-cased'\n",
    "MODEL_TRAINED_PATH: str = os.path.join(GDRIVE_PATH, 'model', 'base-ner')\n",
    "MODEL_TRAINED_LOG: str = os.path.join(MODEL_TRAINED_PATH, 'trainer.log')\n",
    "LABEL_OUTPUT_PATH: str = os.path.join(MODEL_TRAINED_PATH, 'labelset.txt') \n",
    "MODEL_TRAINED_WNUT_PATH: str = os.path.join(GDRIVE_PATH, 'model', 'base-ner-wnut')\n",
    "MODEL_TRAINED_WNUT_LOG: str = os.path.join(MODEL_TRAINED_WNUT_PATH, 'trainer.log')\n",
    "LABEL_OUTPUT_WNUT_PATH: str = os.path.join(MODEL_TRAINED_WNUT_PATH, 'labelset.txt') \n",
    "\n",
    "PUNCTUATION_LIST = [ ',','.',':',';']\n",
    "\n",
    "CONTROL_TOKENS = ['[PAD]', '[SEP]', '[CLS]' ]\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TrainingBatchExample:\n",
    "    batch_encoding: BatchEncoding\n",
    "    labels: List[List[int]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, batch: Union[BatchEncoding, TrainingBatchExample], labels: List[List[int]]=None):\n",
    "        _encodings: BatchEncoding = None\n",
    "        _labels: List[List[int]] = []\n",
    "\n",
    "        if isinstance(batch, TrainingBatchExample):\n",
    "            _encodings = batch.batch_encoding\n",
    "            _labels = batch.labels\n",
    "        else:\n",
    "            _encodings = batch\n",
    "            _labels = labels\n",
    "\n",
    "        if (\"offset_mapping\" in _encodings):\n",
    "            _encoding.pop(\"offset_mapping\")\n",
    "        self.encodings = _encodings\n",
    "        self.labels = _labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelNER:\n",
    "    \"\"\"\n",
    "        Classe preparada para conter os labels de um treinamento/predição de NER.\n",
    "        Os labels podem vir sem preparação, ou seja, anotações onde somente o nome do label é informado e não estão presentes os prefixos (IOB ou BILOU).\n",
    "\n",
    "        load_from_list e load_from_annotations devem ser utilizados no treinamento e o label set deve ser gravado utilizando save().\n",
    "        No caso de predição ou carga para teste utilizar o load para carregar um label set previamente utilizado.\n",
    "     \n",
    "    \"\"\"\n",
    "\n",
    "    def __str__(self):\n",
    "            return f\"{len(self.labels_to_id)} labels {str(self.labels_to_id)}\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels_to_id)\n",
    "\n",
    "    def __init__(self):\n",
    "        self.labels_to_id = {}\n",
    "        self.ids_to_label = {}\n",
    "        \n",
    "    def get_label_list(self):\n",
    "        return self.labels_to_id.keys()\n",
    "\n",
    "    def get_id_list(self):\n",
    "        return self.ids_to_label.keys()\n",
    "\n",
    "    def load_from_complete_list(self, labels: List[str]) -> None:\n",
    "        '''\n",
    "            Args: \n",
    "                labels(:obj:`List[str]`):\n",
    "                Lista de labels completa, esperado conter O(utside) e os prefixos de cada entidade.\n",
    "            \n",
    "            Carrega a lista de labels \"as is\" sem tratamento.\n",
    "        '''\n",
    "        self.labels_to_id: Dict = {label: id for id, label in enumerate(labels)}\n",
    "        self.ids_to_label:Dict = {id: label for label, id in self.labels_to_id.items()}\n",
    "        self._finaliza_carga_labels()\n",
    "\n",
    "    def load_from_simple_list(self, labels: List[str], ner_label_format: str=FORMATO_NER_IOB) -> None:\n",
    "        '''\n",
    "            Args: \n",
    "                labels(:obj:`List[str]`):\n",
    "                    Lista de labels sem prefixo e não contendo o tipo O(utside).\n",
    "                ner_label_format(:obj:`str`, `optional`, defaults to `\"IOB\"`):\n",
    "                    Formato para classificação dos tokens de uma entidade - IOB ou BILOU\n",
    "            \n",
    "            Inclui o tipo O(utside) e faz a permutação entre labels e os prefixos do formato informado\n",
    "        '''\n",
    "        self.labels_to_id[\"O\"] = 0\n",
    "        self.ids_to_label[0] = \"O\"\n",
    "        num = 0  # in case there are no labels\n",
    "        prefix_list: str = \"BI\" if ner_label_format == FORMATO_NER_IOB else \"BILU\"\n",
    "\n",
    "        for _num, (label, s) in enumerate(itertools.product(labels, prefix_list)):\n",
    "            num = _num + 1  # skip 0\n",
    "            l = f\"{s}-{label}\"\n",
    "            self.labels_to_id[l] = num\n",
    "            self.ids_to_label[num] = l\n",
    "        \n",
    "        self._finaliza_carga_labels()\n",
    "\n",
    "    def load_from_file(self, input_file_path:str) -> None:\n",
    "        '''\n",
    "            Args: \n",
    "                labelset_file(:obj:`str`):\n",
    "                    Nome do arquivo contendo a lista de labels previamente gravado. Muito importante ter sido gravado por essa classe ou ter a garantia que o arquivo está com os labels na ordem correta.\n",
    "            \n",
    "            Carrega o arquivo com os labels ordenados. O arquivo pode ser construido manualmente, mas deve conter um label por linha, na ordem utilizada para treinar o modelo, já que essa ordem foi criada na \n",
    "            extração ou carga dos labels para o treinamento do modelo.\n",
    "        '''\n",
    "        with open(input_file_path, 'r' ) as label_file:\n",
    "            for ind, label in enumerate(label_file):\n",
    "                label = label.strip('\\n')\n",
    "                self.labels_to_id[label] = ind\n",
    "                self.ids_to_label[ind] = label\n",
    "\n",
    "    def _finaliza_carga_labels(self) -> None:\n",
    "        ''' \n",
    "            Adicionar o label de ignorar wordpiece para os casos em que o modelo será treinado nesse formato\n",
    "        '''\n",
    "        self.labels_to_id[IGNORE_LABEL] = IGNORE_LABEL_MODEL_ID\n",
    "        self.ids_to_label[IGNORE_LABEL_MODEL_ID] = IGNORE_LABEL\n",
    "\n",
    "    def save(self, output_file_path: str):\n",
    "        with open(output_file_path, 'w' ) as label_file:\n",
    "            for label in self.labels_to_id:\n",
    "                label_file.write(label)\n",
    "                label_file.write('\\n')    \n",
    "\n",
    "\n",
    "    def convert_label_list_to_id_list(self, lista: List[str]) -> List[int]:\n",
    "        \"\"\"\n",
    "            Converte uma lista de labels nos respectivos id`s. Para processamento no modelo essa conversão precisará ser realizada\n",
    "        \"\"\"\n",
    "        return list(map(self.labels_to_id.get, lista))\n",
    "\n",
    "    def convert_id_list_to_label_list(self, lista: List[int]) -> List[str]:\n",
    "        \"\"\"\n",
    "            Converte uma lista de id`s nos respectivos labels. Para compreensão do resultado retornado pelo modelo essa conversão será necessária.\n",
    "        \"\"\"\n",
    "        return list(map(self.ids_to_label.get, lista))  \n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_tokens(batch_encoding :BatchEncoding, \n",
    "                list_annotations: Union[List[List[Dict]],List[List[str]]], \n",
    "                is_span_annotations: bool=True, \n",
    "                ignore_word_piece: bool = False,\n",
    "                ner_label_format: str=FORMATO_NER_IOB,\n",
    "                label_ner: LabelNER=None) -> TrainingBatchExample:\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Alinhamento dos tokens e respectivos labels para tratar a disparidade gerada pelos Tokenizadores Bert quando geram Worpieces.\n",
    "    As anotações foram criadas levando em conta palavras, mas os tokenizadores incluem partes de palavras (wordpieces), exemplo:\n",
    "    Starbucks --> Star, ##bu, ##cks. A anotação está mapeada para uma entrada de B-Location, contudo três entradas deverão ser tratadas.\n",
    "\n",
    "    Args:\n",
    "        batch_encoding (:obj:`BatchEncoding`):\n",
    "            Batch encoding previamente tokenizado (input_ids, attention_mask). \n",
    "            Contém lista de Encodings, ou seja, cada sentença é um encoding e o BatchEncoding contém todos eles.\n",
    "            O modelo é preparado para receber esse tipo de dado, por isso sua estrutura será preservada.\n",
    "        \n",
    "        is_span_annotations(:obj:`bool`, `optional`, defaults to `True`):\n",
    "            Informa se a lista de anotações está no formato span ou se cada token já está classificado com seu respectivo label.\n",
    "            Se for span então o parametro list_annotations será do tipo List[List[Dict]]\n",
    "            Os spans são entradas com inicio e fim de uma faixa de caracteres onde classificados com a entidadade informada. A classificação nesse caso é somente da entidade, não é esperado prefixo IOB ou BILOU.\n",
    "                \n",
    "            Se NÃO for span então o parametro list_annotations será do tipo List[List[int]]\n",
    "            No caso de tokens já classificados (lista de string) espera-se receber os prefixos IOB ou BILOU.\n",
    "\n",
    "            Ambos os casos a classificação existente está por token, o alinhamento resolverá o problema de alinhamento token --> wordpiece.\n",
    "\n",
    "        ignore_word_piece(:obj:`bool`, `optional`, defaults to `False`):\n",
    "            Informa o que fazer com os tokens wordpiece. Se eles forem ignorados então serão treinados com o label -100 (ignorados), caso contrário serão tratados como tokens normais,\n",
    "            podendo receber I- ou L- (formato BILOU)\n",
    "\n",
    "        ner_label_format(:obj:`bool`, `optional`, defaults to `\"IOB\"`):\n",
    "            Formato de classificação de labels, espera o formato IOB ou BILOU\n",
    "\n",
    "        label_ner(:obj:`LabelNER`):\n",
    "            Objeto da classe LabelNER que contém os labels e seus respectivos id's. Será utilizada para converter os labels de string para seus respectivos identificadores.\n",
    "\n",
    "        Returns:\n",
    "            :obj:`TrainingBatchExamples`:\n",
    "                TrainingBatchExamples contendo o BatchEncoding passado e os labels alinhados\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    list_aligned_labels: List[List[int]] = []\n",
    "\n",
    "    for ind_encoding in range(len(batch_encoding.encodings)):\n",
    "        encoding: Encoding = batch_encoding[ind_encoding]\n",
    "        annotations = list_annotations[ind_encoding]\n",
    "\n",
    "        if is_span_annotations:\n",
    "            aligned_labels_str: List[str] = align_tokens_from_span_annotations(encoding,\n",
    "                                                                               annotations,\n",
    "                                                                               ignore_word_piece,\n",
    "                                                                               ner_label_format)\n",
    "        else:\n",
    "           aligned_labels_str: List[str] = align_tokens_from_token_tags(encoding,\n",
    "                                                                        annotations,\n",
    "                                                                        ignore_word_piece)     \n",
    "           \n",
    "        list_aligned_labels.append(label_ner.convert_label_list_to_id_list(aligned_labels_str))\n",
    "\n",
    "    training_batch = TrainingBatchExample(batch_encoding, list_aligned_labels)\n",
    "    \n",
    "    return training_batch\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_tokens_from_span_annotations(encoding: Encoding, \n",
    "                                       annotations: List[Dict],                                     \n",
    "                                       ignore_word_piece: bool = False,\n",
    "                                       ner_label_format: str=FORMATO_NER_IOB):\n",
    "    \"\"\"\n",
    "\n",
    "    Construção do array de labels de acordo com as anotações por span, tratando alinhamento de tokens com wordpieces.\n",
    "    \n",
    "    Args:\n",
    "        encoding (:obj:`Encoding`):\n",
    "            Enconding da sentença previamente tokenizada (input_ids, attention_mask)            \n",
    "        \n",
    "        annotations(:obj:`List[Dict]`)\n",
    "            Lista de spans das entidades, ou seja, cada entrada do dicionário contém o inicio e fim de uma entidade que pode conter uma ou mais palavras.\n",
    "            A função espera receber anotações com as seguintes entradas:\n",
    "                - start - inicio do span\n",
    "                - end - fim do span\n",
    "                - label - label do span. Não é esperado que o label contenha os prefixos IOB ou BILOU, somente o nome do label.\n",
    "\n",
    "        ignore_word_piece(:obj:`bool`, `optional`, defaults to `False`):\n",
    "            Informa o que fazer com os tokens wordpiece. Se eles forem ignorados então serão treinados com o label -100 (ignorados), caso contrário serão tratados como tokens normais,\n",
    "            podendo receber I- ou L- (formato BILOU)\n",
    "\n",
    "        ner_label_format(:obj:`bool`, `optional`, defaults to `\"IOB\"`):\n",
    "            Formato de classificação de labels, espera o formato IOB ou BILOU\n",
    "\n",
    "        Returns:\n",
    "            :obj:`List[str]`:\n",
    "                labels alinhados com os tokens, ignorando ou incluindo nos wordpieces na classificação (parametro ignore_word_piece).\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    # Inicialização com BILOU e ajusta caso necessário\n",
    "    unique_prefix: str='U'\n",
    "    begin_prefix: str='B'\n",
    "    inside_prefix: str='I'\n",
    "    last_prefix: str='L'\n",
    "\n",
    "    if ner_label_format == FORMATO_NER_IOB:\n",
    "        unique_prefix = 'B'\n",
    "        last_prefix = 'I'\n",
    "\n",
    "    tokens = encoding.tokens\n",
    "    #print(tokens)\n",
    "    aligned_labels: List[str] = [\"O\"] * len(tokens)  # Make a list to store our labels the same length as our tokens\n",
    "    for anno in annotations:\n",
    "        annotation_token_ix_set = (set())  # A set that stores the token indices of the annotation\n",
    "        for char_ix in range(anno[\"start\"], anno[\"end\"]):\n",
    "            token_ix = encoding.char_to_token(char_ix)\n",
    "            if token_ix is not None:\n",
    "                if not tokens[token_ix] in PUNCTUATION_LIST: # alguns datasets incluem caracteres de pontuação na entidade por falha nas anotações\n",
    "                    annotation_token_ix_set.add(token_ix)\n",
    "\n",
    "        if len(annotation_token_ix_set) == 1:\n",
    "            # If there is only one token\n",
    "            token_ix = annotation_token_ix_set.pop()\n",
    "            aligned_labels[token_ix] = f\"{unique_prefix}-{anno['label']}\"\n",
    "\n",
    "        else:\n",
    "            last_token_in_anno_ix = len(annotation_token_ix_set) - 1\n",
    "            for num, token_ix in enumerate(sorted(annotation_token_ix_set)):\n",
    "                ignorar_token: bool=False\n",
    "\n",
    "                #tratamento worpiece\n",
    "                if ignore_word_piece:\n",
    "                    if token_ix > 1: #[CLS] e o primeiro token não serão wordpieces com certeza e o offets deles compromete a lógica [CLS] (0,0) [1o token] (0,1)\n",
    "                        offset_ini = encoding.offsets[token_ix][0]\n",
    "                        offset_end_anterior = encoding.offsets[token_ix-1][1]\n",
    "                        if offset_ini == offset_end_anterior:\n",
    "                            ignorar_token = True\n",
    "                            aligned_labels[token_ix] = IGNORE_LABEL        \n",
    "\n",
    "                if not ignorar_token:\n",
    "                    if num == 0:\n",
    "                        prefix = begin_prefix\n",
    "                    elif num == last_token_in_anno_ix:\n",
    "                        prefix = last_prefix\n",
    "                    else:\n",
    "                        prefix = inside_prefix\n",
    "                    aligned_labels[token_ix] = f\"{prefix}-{anno['label']}\"\n",
    "    return aligned_labels\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_tokens_from_token_tags(encoding: Encoding, tag_list: List[str], ignore_word_piece: bool = False):\n",
    "    \"\"\"\n",
    "        Anotações por tokens são feitas em arquivos já tokenizados, não são strings, são linhas de tokens e classificação. O offset para identificação de wordpiece \n",
    "        deve ser tratado diferente das strings com anotações por span. Tokens que possuem o primeiro item do offset > 0 e o segundo item diferente de zero são wordpiece \n",
    "        (a segunda parte da crítica seria para o [CLS] ou [SEP]).\n",
    "        Somente o formato IOB será tratado nessa função de alinhamento.\n",
    "\n",
    "        Args:\n",
    "        encoding (:obj:`Encoding`):\n",
    "            Enconding da sentença previamente tokenizada (input_ids, attention_mask)            \n",
    "        \n",
    "        tag_list(:obj:`List[str]`)\n",
    "            Lista com os labels por token. Não possui o tratamento do worpiece. len(label_list) <= len(enconding.tokens)\n",
    "\n",
    "        ignore_word_piece(:obj:`bool`, `optional`, defaults to `False`):\n",
    "            Informa o que fazer com os tokens wordpiece. Se eles forem ignorados então serão treinados com o label -100 (ignorados), caso contrário serão tratados como tokens normais,\n",
    "            podendo receber I- ou L- (formato BILOU)\n",
    "        \n",
    "        Returns:\n",
    "            :obj:`List[str]`:\n",
    "                labels alinhados com os tokens, ignorando ou incluindo nos wordpieces na classificação (parametro ignore_word_piece).\n",
    "    \"\"\"\n",
    "\n",
    "    aligned_labels: List[str] = [\"O\"] * len(encoding.tokens)\n",
    "    ind_label: int = 0\n",
    "    last_token_label: str = None\n",
    "\n",
    "    for ind_token, token_input_id in enumerate(encoding.ids):\n",
    "        offsets = encoding.offsets\n",
    "        if ind_token == 0: #ignora o [CLS]\n",
    "            continue\n",
    "        if (offsets[ind_token][0] > 0):\n",
    "            if last_token_label is not None:\n",
    "                if ignore_word_piece:\n",
    "                    aligned_labels[ind_token] = IGNORE_LABEL\n",
    "                else:\n",
    "                    aligned_labels[ind_token] = last_token_label.replace(\"B-\",\"I-\") \n",
    "        else:\n",
    "            # tratamento dos [PAD]`s que vão além da lista de labels\n",
    "            label: str = tag_list[ind_label] if ind_label < len(tag_list) else \"O\"\n",
    "            aligned_labels[ind_token] = label\n",
    "            last_token_label = label if label != \"O\" else None                    \n",
    "            ind_label = ind_label + 1\n",
    "    \n",
    "    return aligned_labels\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liberar Recursos da GPU\n",
    "def destroy_model(model: Union[DistilBertForTokenClassification,BertForTokenClassification]):\n",
    "    del model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "def destroy_tokenizer(tokenizer: Union[BertTokenizerFast, DistilBertTokenizerFast]):\n",
    "    del tokenizer\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepara_NER_prediction_for_metrics(tokenizer: Union[BertTokenizerFast, DistilBertTokenizerFast], \n",
    "                                       batch_encoding: BatchEncoding, \n",
    "                                       test_labels: numpy.ndarray, \n",
    "                                       pred_labels: numpy.ndarray,\n",
    "                                       ignorar_wordpiece: bool):\n",
    "    \"\"\"\n",
    "        Ajusta da predição realizada pelo NER para avaliação das métricas, tratando wordpieces caso necessário.\n",
    "        Os seguintes tokens de controle devem ser ignorados: [PAD], [SEP], [CLS]. Ignorar representa atribuir o valor correto à predição, \n",
    "        já que a predição que eventualmente foi predita será ignorada na métrica do teste e no uso ordinário.\n",
    "\n",
    "        Args:\n",
    "            tokenizer (:obj:`Union[BertTokenizerFast,DistilBertTokenizerFast]`):\n",
    "                Tokenizer utiilzado no modelo e que tokenizou o batch_encoding.\n",
    "\n",
    "            batch_encoding (:obj:`BatchEncoding`):\n",
    "                Batch enconding das sentenças tokenizadas utilizando o tokenizer passado por parametro. Será usado caso os wordpieces sejam ignorados.\n",
    "            \n",
    "            test_labels (:obj:`numpy.ndarray(int)`):\n",
    "                Array com os valores corretos dos labels.\n",
    "            \n",
    "            pred_labels (:obj:`numpy.ndarray(int)`):\n",
    "                Array com os valores inferido pelo modelo.\n",
    "\n",
    "            ignorar_wordpiece (:obj:`bool`):\n",
    "                Caso afirmativo os wordpieces serão ignorados e receberão o valor correto, já que o importante seria sua primeira parte, que identifica o token\n",
    "\n",
    "            \n",
    "        Returns:\n",
    "            :obj:`numpy.ndarray(int)`:\n",
    "                Vetor de predição preparado para aplicação de métricas.\n",
    "    \"\"\"\n",
    "    control_encodings:BatchEncoding = tokenizer(CONTROL_TOKENS)\n",
    "    # [CLS] e [SEP] são adicionados pelo tokenizador gerando 3 * numero de tokens de controle, por isso foi gerado um set\n",
    "    ignored_tokens = set([token_id for control_sent in control_encodings.input_ids for token_id in control_sent])\n",
    "    \n",
    "    for ind_encoding in range(len(batch_encoding.encodings)):\n",
    "        encoding:Encoding = batch_encoding[ind_encoding]\n",
    "        \n",
    "        for ind_token,input_id in enumerate(encoding.ids):\n",
    "            if input_id in ignored_tokens:\n",
    "                if pred_labels[ind_encoding][ind_token] != test_labels[ind_encoding][ind_token]:\n",
    "                    #print(input_id,' [', ind_encoding, ',', ind_token, '] -', pred_labels[ind_encoding][ind_token], '--> ', test_labels[ind_encoding][ind_token] )\n",
    "                    pred_labels[ind_encoding][ind_token] = test_labels[ind_encoding][ind_token]\n",
    "\n",
    "\n",
    "        if ignorar_wordpiece:\n",
    "            for ind_token, offset in enumerate(encoding.offsets):\n",
    "                if ind_token <=1:\n",
    "                    continue\n",
    "                offset_ini = encoding.offsets[ind_token][0]\n",
    "                offset_end_anterior = encoding.offsets[ind_token-1][1]\n",
    "                if offset_ini == offset_end_anterior:\n",
    "                    pred_labels[ind_encoding,ind_token] = test_labels[ind_encoding,ind_token]\n",
    "\n",
    "    return pred_labels\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retorna os tensores que estão em uso na memória da GPU\n",
    "\n",
    "def get_gpu_memory_status():\n",
    "    total = (torch.cuda.get_device_properties(0).total_memory)/(1024 **2)\n",
    "    reserved = (torch.cuda.memory_reserved(0))/(1024 **2)\n",
    "    allocated = (torch.cuda.memory_allocated(0))/(1024 **2)\n",
    "    return f\"Total: {total:.2f} | Reserved: {reserved:.2f} | Allocated: {allocated:.2f}\"\n",
    "\n",
    "def print_gpu_use():\n",
    "    result = []\n",
    "    for tracked_object in gc.get_objects():\n",
    "        if torch.is_tensor(tracked_object):\n",
    "            shape = tracked_object.shape\n",
    "            result.append({\n",
    "                'name': type(tracked_object).__name__,\n",
    "                '1d': len(shape)==1,\n",
    "                '2d': len(shape)==2,\n",
    "                'nrows': shape[0] if (len(shape) > 0) else None,\n",
    "                'ncols': shape[1] if (len(shape) > 1) else None,\n",
    "                'gpu': tracked_object.is_cuda,\n",
    "                'pinned': tracked_object.is_pinned()\n",
    "            })\n",
    "        \n",
    "    d = pd.DataFrame(result)\n",
    "    d.groupby('name')['gpu', 'pinned', '1d', '2d'].sum()\n",
    "    print(d)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grafico_trainer_loss(trainer_loss: numpy.ndarray, validation_loss: numpy.ndarray):\n",
    "    # Use plot styling from seaborn.\n",
    "    sns.set(style='darkgrid')\n",
    "\n",
    "    # Increase the plot size and font size.\n",
    "    sns.set(font_scale=1.5)\n",
    "    plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "    # Plot the learning curve.\n",
    "    plt.plot(trainer_loss[:,0],trainer_loss[:,1] , label=\"training loss\")\n",
    "    plt.plot(validation_loss[:,0], validation_loss[:,1] , label=\"validation loss\")\n",
    "\n",
    "    # Label the plot.\n",
    "    plt.title(\"Learning curve\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "     \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Treinamento com Anotações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/eddygiusepe/Imagens/Eddy_codigos/NLP_Transformers/NER_BERT_Deep_Learning/basic_NER_BERT/dataset/ddi_train.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# carregamento e alteração do campo para ficar similar ao esperado pela função que faz os alinhamentos\u001b[39;00m\n\u001b[1;32m      2\u001b[0m label_set: Set[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n\u001b[0;32m----> 3\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(DATASET_DDI_TRAIN) \u001b[39mas\u001b[39;00m json_ds_file:\n\u001b[1;32m      4\u001b[0m     raw \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(json_ds_file)\n\u001b[1;32m      5\u001b[0m     \u001b[39mfor\u001b[39;00m example \u001b[39min\u001b[39;00m raw:\n\u001b[1;32m      6\u001b[0m         \u001b[39m# our simple implementation expects the label to be called label, so we adjust the original data\u001b[39;00m\n",
      "File \u001b[0;32m~/Imagens/Eddy_codigos/NLP_Transformers/venv_transformers/lib/python3.8/site-packages/IPython/core/interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[1;32m    276\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    277\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    279\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m     )\n\u001b[0;32m--> 282\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/eddygiusepe/Imagens/Eddy_codigos/NLP_Transformers/NER_BERT_Deep_Learning/basic_NER_BERT/dataset/ddi_train.json'"
     ]
    }
   ],
   "source": [
    "# carregamento e alteração do campo para ficar similar ao esperado pela função que faz os alinhamentos\n",
    "label_set: Set[str] = set()\n",
    "with open(DATASET_DDI_TRAIN) as json_ds_file:\n",
    "    raw = json.load(json_ds_file)\n",
    "    for example in raw:\n",
    "        # our simple implementation expects the label to be called label, so we adjust the original data\n",
    "        for anno in example[\"annotations\"]:\n",
    "            anno[\"label\"] = anno[\"tag\"]\n",
    "            label_set.add(anno[\"label\"])\n",
    "\n",
    "label_list: List[str] = list(label_set)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "744cf54c6e08528d59b17d69482cd9cfecb0ea2489e1abb457edfe7bddc9bd30"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
